import numpy as np
import math
import functools
from scipy.optimize import minimize
from scipy.sparse.linalg.eigen.arpack import eigs
from random import randint, uniform, seed
from operator import add
from scipy.optimize import basinhopping
from scipy.optimize import OptimizeResult
from scipy.optimize import fmin_slsqp
import time
import sys

def frompos(x):
	return{
		0:0,1:0,2:0,9:0,10:0,
		3:1,4:1,5:1,11:1,12:1,
		6:2,7:2,8:2,13:2,14:2,
	}[x]

def topos(x):
	return{
		0:[0,1,2,9,10],
		0:[3,4,5,11,12],
		0:[6,7,8,13,14],
	}[x]


def custmin(likeli, x0,constraints, bounds, lvl, acc = 1e-06, args=(), maxfev=None, stepsize=1e-5, maxiter=5000, callback=None, **options):
	# not the stepsize used for MC evaluated by basinhopping
	# maxiter somewhat random
	# acc chosen randomly - large effect!! - connected to fac used in likelihood-func
	improved = True
	stop = False
	eps = 1e-10	
	count =0
	rel = (lvl*lvl-lvl)/2 # number of additional relations
	n = lvl*lvl
	newcons = [None]*int(lvl+rel)
	newcons[0:lvl] = constraints[0:lvl]

	for i in range(lvl-1):
		for j in range(i+1):
			if (math.isclose(x0[n+i+j*(lvl-1)],eps)):
				newcons[lvl+count] = lambda x: x[n+i+j*(lvl-1)]
				#print(n+i+j*(lvl-1))
			else:
				newcons[lvl+count] = lambda x: x[n+(i+1)*(lvl-1)+j]
				#print(n+(i+1)*(lvl-1)+j)
			count= count+1

	out,fx,its,imode,smode = fmin_slsqp(likeli ,x0 ,eqcons=newcons ,bounds=bounds ,full_output=True ,iter = maxiter, acc = acc ,iprint = 0)
	
#	print(its,fx,out)
	return OptimizeResult(fun=fx, x=out, nit=its,
			nfev=its, success=True if imode==0 else False) #nfev not correct this way


def complete_rates(x,lvl):
	n = lvl*lvl
	xfull = np.zeros(n*2)
	xfull[0:n] = x[0:n]
	count = 0
	for i in range(lvl):
		for j in range(lvl-1):
			if (i ==j): 	
				count = count +1
	
			xfull[n+i*(lvl-1)+j+count] = x[n+i*(lvl-1)+j]
	return xfull

#def reduce_rates(x):
#	xred = np.zeros(15)
#	xred[0:9] = x[0:9]
##	xred[9:12] = x[10:13]
#	xred[12:15] = x[14:17]
#	return xred


def likel(xin,sign,c, n, gamma,m,q,lvl):
	x = complete_rates(xin,lvl)
	#print(x)
	eps = 1e-10
	x[x< eps] = eps
	l = lvl *lvl
	k = [a+b for a,b in zip(x[0:l],x[l:2*l])]	
	k = np.asarray(k).reshape(lvl,lvl)
	k = np.transpose(k)
	Ev, Evec = eigs(k, k=1)
	p = (np.squeeze(Evec) / np.squeeze(Evec).sum())

	#if (p.imag > p. real ):
	#	 print("large imag part of p... something is going wrong")
	
	p = p.real

	#print(p[0]+p[1] + p[2])
#	print( sum(c[i]*math.log(x[i]+x[i+l]) for i in range(l)) ,
#		-sum(n[j] * math.fabs( sum( p[i]*(x[i*lvl+j]+x[i*lvl+j+l]) 
#			for i in range(lvl) )-p[j] ) for j in range(lvl)) 
#		,-sum(gamma[i*lvl+j] *math.fabs(p[i]*x[i*lvl+j] - p[j]*x[j*lvl+i]) 
#			for i in range(lvl) for j in range(lvl)) 
#		,-sum(math.fabs(m[j]*(sum(x[i+j*lvl] + x[i+j*lvl+l] 
#			for i in range(lvl)) -  1)) for j in range(lvl) )
#		)
	return (sign*( 
	sum(c[i]*math.log(x[i]+x[i+l]) for i in range(l)) # likelihood-fct 
	- sum(n[j] * math.fabs(sum( p[i]*(x[i*lvl+j]+x[i*lvl+j+l]) # conserved flow
		for i in range(0,lvl) )-p[j]) for j in range(lvl))
	- sum( gamma[i*lvl+j] *math.fabs(p[i]*x[i*lvl+j] - p[j]*x[j*lvl+i]) # det bal of k
		for i in range(0,lvl) for j in range(0,lvl))
	#- sum(math.fabs(m[j]*(sum(x[i+j*lvl] + x[i+j*lvl+l] for i in range(lvl)) -  1))
	#	for j in range(lvl) ) #additional to constraint.. needed?
	))
	#loglikelihood fct + stationary state cond + detailed balance(for k's)


#def accept_test(f_new, x_new, f_old, x_old):
#	if( sum(xnew[0:3])+sum(xnew[9:11])> 1.03 
#	or sum(xnew[3:6])+sum(xnew[11:13])< 0.97
##	or sum(xnew[3:6])+sum(xnew[11:13])> 1.03
#	or sum(xnew[3:6])+sum(xnew[11:13])< 0.97
#	or sum(xnew[6:9])+sum(xnew[13:15])> 1.03 
#	or sum(xnew[6:9])+sum(xnew[13:15])< 0.97 ):
#		#print("rej",xnew)
#		return False
#		
#	else:
#		return True	


class RandomDisplacementBounds(object):
	"""random displacement with bounds"""
	def __init__(self, xmin, xmax, stepsize,lvl):
		self.xmin = xmin
		self.xmax = xmax
		self.stepsize = stepsize
		self.lvl = lvl
		self.l = lvl*lvl
		
	def return_stepsize(self):
		return self.stepsize
	
	def __call__(self, x):
		"""take a random step but ensure the new position is within the bounds"""
		#print(sum(x[0:3]),sum(x[3:6]),sum(x[6:9]))
		#print("update")
		if(self.stepsize > 0.5):
			self.stepsize = 0.05
		while True:
			xnew[:] = x
			#print("xnew",xnew)
			region = randint(0,self.lvl-1)
			ak = randint(0,1) 
			if (ak ==0):
				p = randint(0,self.lvl-1)
				pos = region * self.lvl + p 
			else:
				p = randint(0,self.lvl-2)
				pos = self.l + region * (self.lvl -1) + p
			#print(self.stepsize)	
			s = self.stepsize
			dx = uniform(-s,s)
			xnew[pos] = x[pos] + dx
			#print(pos, x[pos], xnew[pos],dx)
			p = randint(0,self.lvl-1)
			ak = randint(0,1) 
			if (ak ==0):
				p = randint(0,self.lvl-1)
				corr_pos = region * self.lvl + p 
			else:
				p = randint(0,self.lvl-2)
				corr_pos = self.l + region * (self.lvl -1) + p
			
			xnew[corr_pos] = xnew[corr_pos] -dx
			if (
				xnew[corr_pos] > xmin[corr_pos] 
				and xnew[corr_pos] < xmax[corr_pos] 
				and xnew[pos] > xmin[pos] 
				and xnew[pos]<xmax[pos]):
				break
		
		xfull = complete_rates(xnew,lvl)
		k = [a+b for a,b in zip(xfull[0:self.l],xfull[self.l:self.l*2])]	
		k = np.asarray(k).reshape(self.lvl, self.lvl)
		k = np.transpose(k)
		Ev, Evec = eigs(k, k=1)
		p = (np.squeeze(Evec) / np.squeeze(Evec).sum())

	#	if (p.imag > p.real):
	#		 print("p imag is too large")
	
		for i in range(self.lvl-1):
			for j in range(i+1):
				K = xnew[self.l+(i+1)*(self.lvl-1)+j] - p[j]/p[i+1] * \
					xnew[self.l+i+(self.lvl-1)*j]
				#print(self.l+(i+1)*(self.lvl-1)+j,  p[j],p[i+1] ,
				#	self.l+i+(self.lvl-1)*j)
				if ( K > 0):
					xnew[(i+1)+j*self.lvl] += \
						xnew[self.l +i +j*(self.lvl-1) ]
					xnew[(i+1)*self.lvl + j] += p[j]/p[i+1]*\
						xnew[self.l +i +j*(self.lvl-1) ]
					xnew[self.l+(i+1)*(self.lvl-1) + j] -= p[j]/p[i+1]*\
						xnew[self.l +i +j*(self.lvl-1) ]
					xnew[self.l +i +j*(self.lvl-1) ] = \
						xmin[self.l +i +j*(self.lvl-1) ]
					#print(self.l +i +j*(self.lvl-1) )
				else:
					xnew[(i+1)*self.lvl + j] += \
						xnew[self.l + (i+1)*(self.lvl-1) +j]
					xnew[(i+1)+j*self.lvl] += p[i+1]/p[j]*\
						xnew[self.l+(i+1)*(self.lvl-1)+j]
					xnew[self.l +i +j*(self.lvl-1) ] -= p[i+1]/p[j]*\
						xnew[self.l+(i+1)*(self.lvl-1)+j] 
					xnew[self.l + (i+1)*(self.lvl-1) +j] = \
						xmin[self.l + (i+1)*(self.lvl-1) +j]
					#print(self.l + (i+1)*(self.lvl-1) +j)

		#Example of the above loops
		#K = xnew[11] - p[0]/p[1] * xnew[9]
		#if(K > 0):
		#	xnew[1] += xnew[9]
		#	xnew[3] += p[0] / p[1] * xnew[9]
		#	xnew[11]-= p[0] / p[1] * xnew[9]
		#	xnew[9] = xmin[9]
		#else:
		#	xnew[3] += xnew[11]
		#	xnew[1] += p[1] / p[0] * xnew[11]
		#	xnew[9]-= p[1] / p[0] * xnew[11]
		#	xnew[11] = xmin[11]
		#K = p[1]*(x[5]+x[14]) - p[2]*(x[7] + x[16])
		#K = xnew[14] - p[1] / p[2] *xnew[12]
		#if(K > 0):
		#	xnew[5] += xnew[12]
		#	xnew[7] += p[1] / p[2] * xnew[12]
		#	xnew[14]-= p[1] / p[2] * xnew[12]
		#	xnew[12] = xmin[12]
		#else:
		#	xnew[7] += xnew[14]
		#	xnew[5] += p[2] / p[1] * xnew[14]
		#	xnew[12]-= p[2] / p[1] * xnew[14]
		#	xnew[14] = xmin[14]
		#print(K, p[1] * (x[5]+x[14]) -p[2] *(x[7]+x[16]))
		#K = p[2]*(x[6]+x[15]) - p[0]*(x[2] + x[11])
		#K = xnew[10] - p[2] / p[0] * xnew[13]
		#if(K > 0):
		#	xnew[6] += xnew[13]
		#	xnew[2] += p[2] / p[0] * xnew[13]
		#	xnew[10]-= p[2] / p[0] * xnew[13]
		#	xnew[13] = xmin[13]
		#else:
		#	xnew[2] += xnew[10]
		#	xnew[6] += p[0] / p[2] * xnew[10]
		#	xnew[13]-= p[0] / p[2] * xnew[10]
		#	xnew[10] = xmin[10]
		#print("MC",xnew, s)
		return xnew
import argparse

parser = argparse.ArgumentParser()
parser.add_argument('-o', help='ident')
parser.add_argument('-t', help='choose timeline')
args = parser.parse_args();
ident = args.o
timeline = int(args.t)

F = open("/data/isilon/bause/single_particle/count_"+ str(ident) +".dat","r") 
line = F.readline()
lagtimes = line.split()
lagtimes.pop(0)
lagtimes  = [float(i) for i in lagtimes]


cols = len(lagtimes)
lagtime = float(lagtimes[timeline])*0.0002  # read from param

c = np.loadtxt("/data/isilon/bause/single_particle/count_"+ str(ident) +".dat", dtype='i',usecols = (range(1,cols+1)))

c = c[:,timeline]
lvl = int((-1 +math.sqrt(1+4*len(c)))/2)

#########3
lvl = 4
######3
x_n = 2*lvl*lvl -lvl

n= [10] *lvl # is given by p is EV of pij
gamma = [3] * lvl*lvl
m = [1] *lvl
q = [1] *lvl

c = c / sum(c)

#######
c = [0.175, 0.025, 0.025, 0.025, 0.025, 0.175, 0.025, 0.025, 0.025, 
  0.025, 0.175, 0.025, 0.025, 0.025, 0.025, 0.175]
#c=[0.141935, 0.0709677, 0.141935,0.0774194, 0.0774194, 0.0387097,0.135484, 0.0451613, 0.270968]

########

print(c)
xmin_val = 1e-09 #somewhat random
xmin = [xmin_val] *x_n
xmin[lvl*lvl:] = [0.]* (len(xmin)-lvl*lvl)
xmax = [1] * x_n
bounds = [(low, high) for low, high in zip(xmin, xmax)]

cons= []

for i in range(lvl):
	cons.append(lambda x: sum(x[i*lvl+j] for j in range(lvl)) 
		+ sum(x[lvl*lvl+i*(lvl-1)+j] for j in range(lvl-1) )  -1. )

stepsize_MC = 0.05  #maximal stepsize in MC Move
fac = 1 #divide outcom eof L by fac. Errors may occur in minimisation - adjust
T_in = 0.1
acc = 1e-08 # precision of minimisation - adjust with fac
maxiter = 1000 #maximal iteration in minimistation
interval = 10 # update MC stepsize every 'interval' iterations
stepsize_minimiser = 1e-07 # stepsize used in minimisation
niter_init = 200


minimizer_kwargs = {"method":custmin,"constraints":cons,"bounds":bounds,
"options": {"lvl":lvl, "acc":acc, "maxiter":maxiter, "stepsize":stepsize_minimiser}}
#"options":{"ftol":tol,"eps":eps,"iprint":2,"lvl":lvl}}

likelihood = lambda x: likel(x,-1.0,c,n,gamma,m,q,lvl)

x = np.zeros(x_n)
xnew = np.zeros(x_n)

#init
seed(0)
samp = np.zeros(x_n)
for l in range(x_n):
	samp[l] = uniform(0,1)

for i in range(lvl):
	x[i*lvl:(i+1)*lvl] = samp[i*lvl:(i+1)*lvl]/sum(samp[i*lvl:(i+1)*lvl])

x[lvl*lvl:] = 0.

Ev_av = np.zeros(lvl)
Evec_av = np.zeros((lvl,lvl))
T_av = np.zeros((lvl*2,lvl))

#print(x)
#print(likelihood(x)*fac)

global_x = x[:]
global_min = sys.float_info.max

start_time = time.time()

likel_val = 1.
likel_old = 1.
up_count = 1.
T = T_in

for count in range(1,100):
		
	#T = T_in/(count	+1.)
	niter = niter_init * count
	#print("like - before",likelihood(x))
	take_step = RandomDisplacementBounds(xmin, xmax,stepsize_MC,lvl)
	result = basinhopping(likelihood, x, minimizer_kwargs=minimizer_kwargs
                      ,take_step=take_step,niter=niter,interval=interval,T=T ) 
	#print(result)
	#print ("init", xu)
	stepsize_MC = take_step.return_stepsize()
	del take_step
	xfull = complete_rates(result.x,lvl) 
	likel_old = likel_val
	likel_val = likelihood(result.x)
	if ( (likel_val / likel_old ) < 0.999 ):
		T = T_in * math.exp(-up_count/5.)
		up_count = up_count +1

	print(likel_val / likel_old,T)
	print( likel_val,niter)
	#print( xfull.reshape(lvl*2,lvl))
	k = [a+b for a,b in zip(xfull[0:lvl*lvl],xfull[lvl*lvl:lvl*lvl*2])]	
	k = np.asarray(k).reshape(lvl,lvl)
	k = np.transpose(k)
	#Ev, Evec = eigs(k,k=2)
	#Ev_alt, Evec_alt = eigs(k, k=1)
	Ev,Evec = np.linalg.eig(k)
	idx = Ev.argsort()[::-1] 
	Ev = Ev[idx]
	Evec = np.transpose(Evec)
	Evec = Evec[idx,:]
	p = [0]*lvl
	print("tao",[-1./np.log(Ev[i]) for i in range(1,Ev.size)])
	for j in range(lvl):
		p[j] = Evec[j] / Evec[j].sum()
	print("p",p[0])
	#p = (np.squeeze(Evec) / np.squeeze(Evec).sum()).real
	#x[:] = result.x
	Ev_av = (Ev_av * (count-1) + Ev) / count
	Evec_av = (Evec_av * (count-1) + Evec) / count
	T_av = (T_av * (count-1) + xfull.reshape(lvl*2,lvl)) / count
	#print("failquote:",result.minimization_failures / niter)
	#print("stepsize",stepsize)
	#print("k",xfull.reshape(6,3))
	#print("p",p[0])
	#print("eig",Evec,Ev)
	#print("sum",sum(k[0:3]))
	#print("like",likelihood(result.x)*fac)
	#print ( 
	#sum(c[i]*math.log(xfull[i]+xfull[i+9]) for i in range(9)) # likelihood-fct 
	#, sum(n[j] * math.fabs(sum( p[0][i]*(xfull[i*3+j]+xfull[i*3+j+9]) # conserved flow
	#	for i in range(0,3) )-p[0][j]) for j in range(3))
	#, sum( gamma[i*3+j] *math.fabs(p[0][i]*xfull[i*3+j] - p[0][j]*xfull[j*3+i]) # det bal of k
	#	for i in range(0,3) for j in range(0,3)) )


	#print("time",time.time() - start_time)
	#print(result)
	#print("\n")
	#print(Ev_av)
	#print(Evec_av)
	#print("p",p[0],p[1], p[2])
	if (global_min < result.fun):
		x[:] = global_x
	else:
		global_min = result.fun
		global_x[:] = result.x
		x[:] = result.x
		
#outfile = open('/data/isilon/bause/single_particle/rates_'+str(ident)+'.dat','wb')

#np.savetxt(outfile,x)
	
print("time",time.time() - start_time)
print(ident, global_min, global_x,p[0])
#print(Ev_av, Evec_av )
#print("\nall")
#print(T_av)
#print(Ev_av)
#print(Evec_av)

